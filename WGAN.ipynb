{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9DcWSDcAyN3+ZeekpYeEa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alkokt/PengantarDeepLearning2022/blob/master/WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wasserstein GAN (WGAN)"
      ],
      "metadata": {
        "id": "l9Z1r7-na4TJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prerequest**"
      ],
      "metadata": {
        "id": "Kwq1u4dhX-oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwQzyTSVX0aF",
        "outputId": "b5d81d8d-e779-4028-d777-3f672db4769f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import All prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ROOT = \"/content/drive/My Drive/Colab Notebooks/DSC_UI_GAN/Batch1/W2/WGAN\"\n",
        "sample_dir = os.path.join(ROOT, 'sample')\n",
        "# Make dir if no exist\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)"
      ],
      "metadata": {
        "id": "2o1kKgrXYTJd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**"
      ],
      "metadata": {
        "id": "mvrUQ-bGX-E4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "metadata": {
        "id": "7qFTjwA-YafP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Print example\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "Kcv6StkkYlOs",
        "outputId": "3195708e-adde-4899-daf2-54fd91a5653d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Models**"
      ],
      "metadata": {
        "id": "BKvsxf5zYnwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator Model"
      ],
      "metadata": {
        "id": "IAganMZLYrZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(g_input_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, g_output_dim), \n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        image = self.model(z)\n",
        "        image = image.view(image.size(0), -1)\n",
        "        return image"
      ],
      "metadata": {
        "id": "LiRo_RRaYwYm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator Model"
      ],
      "metadata": {
        "id": "f3jBqqjrY_Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(d_input_dim, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        img_flat = image.view(image.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "WAfkhc-uY8gj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build network**"
      ],
      "metadata": {
        "id": "vhftWOT4ZERP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build network\n",
        "z_dim = 100\n",
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
        "\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEHpE2KvZCVH",
        "outputId": "d19c46bf-27f0-43b0-ce77-efdbc147b74a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G, D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ezCRD7rZJQQ",
        "outputId": "e234a368-2759-4798-ffd6-620c4d535171"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (12): Tanh()\n",
            "  )\n",
            ") Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
            "    (5): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Process**"
      ],
      "metadata": {
        "id": "FD_7Gjy6ZNeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "lr = 0.00005\n",
        "n_critic =  5\n",
        "clip_value = 0.01\n",
        "G_optimizer = torch.optim.RMSprop(params=[p for p in G.parameters() if p.requires_grad], lr=lr)\n",
        "D_optimizer = torch.optim.RMSprop(params=[p for p in D.parameters() if p.requires_grad], lr=lr)"
      ],
      "metadata": {
        "id": "F2pgVavhZRNN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "epochs = 200\n",
        "batches_done = 0\n",
        "list_loss_D = []\n",
        "list_loss_G = []\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        D_optimizer.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], z_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        fake_imgs = G(z).detach()\n",
        "        # Adversarial loss\n",
        "        d_loss = -torch.mean(D(real_imgs)) + torch.mean(D(fake_imgs))\n",
        "\n",
        "        d_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # Clip weights of discriminator\n",
        "        for p in D.parameters():\n",
        "            p.data.clamp_(-clip_value, clip_value)\n",
        "\n",
        "        # Train the generator every n_critic iterations\n",
        "        if i % n_critic == 0:\n",
        "\n",
        "            # -----------------\n",
        "            #  Train Generator\n",
        "            # -----------------\n",
        "\n",
        "            G_optimizer.zero_grad()\n",
        "\n",
        "            # Generate a batch of images\n",
        "            gen_imgs = G(z)\n",
        "            # Adversarial loss\n",
        "            g_loss = -torch.mean(D(gen_imgs))\n",
        "\n",
        "\n",
        "            g_loss.backward()\n",
        "            G_optimizer.step()\n",
        "\n",
        "            # add loss to list\n",
        "            list_loss_D.append(d_loss.item())\n",
        "            list_loss_G.append(g_loss.item())\n",
        "        \n",
        "        if i % 300 == 0:\n",
        "            print(\n",
        "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "              % (epoch, epochs, i, len(train_loader), d_loss.item(), g_loss.item()))\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        save_image(gen_imgs.view(gen_imgs.size(0), 1, 28, 28), os.path.join(sample_dir, \"%d.png\" % epoch), nrow=5, normalize=True)\n",
        "\n",
        "torch.save(G, os.path.join(ROOT, 'G.pt'))\n",
        "torch.save(D, os.path.join(ROOT, 'D.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaevBns4ZTct",
        "outputId": "a1778dc1-adb3-4101-987b-15b863308f55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/200] [Batch 0/600] [D loss: -0.050945] [G loss: -0.502989]\n",
            "[Epoch 0/200] [Batch 300/600] [D loss: -0.098372] [G loss: -0.780669]\n",
            "[Epoch 1/200] [Batch 0/600] [D loss: -0.034102] [G loss: -0.761513]\n",
            "[Epoch 1/200] [Batch 300/600] [D loss: -0.042516] [G loss: -0.597099]\n",
            "[Epoch 2/200] [Batch 0/600] [D loss: -0.123023] [G loss: -0.461854]\n",
            "[Epoch 2/200] [Batch 300/600] [D loss: -0.112997] [G loss: -0.500842]\n",
            "[Epoch 3/200] [Batch 0/600] [D loss: -0.161778] [G loss: -0.495281]\n",
            "[Epoch 3/200] [Batch 300/600] [D loss: -0.089781] [G loss: -0.554970]\n",
            "[Epoch 4/200] [Batch 0/600] [D loss: -0.118465] [G loss: -0.491976]\n",
            "[Epoch 4/200] [Batch 300/600] [D loss: -0.114636] [G loss: -0.511078]\n",
            "[Epoch 5/200] [Batch 0/600] [D loss: -0.103833] [G loss: -0.515969]\n",
            "[Epoch 5/200] [Batch 300/600] [D loss: -0.089958] [G loss: -0.515418]\n",
            "[Epoch 6/200] [Batch 0/600] [D loss: -0.109360] [G loss: -0.515723]\n",
            "[Epoch 6/200] [Batch 300/600] [D loss: -0.113047] [G loss: -0.496634]\n",
            "[Epoch 7/200] [Batch 0/600] [D loss: -0.098930] [G loss: -0.496035]\n",
            "[Epoch 7/200] [Batch 300/600] [D loss: -0.096638] [G loss: -0.509314]\n",
            "[Epoch 8/200] [Batch 0/600] [D loss: -0.097505] [G loss: -0.528842]\n",
            "[Epoch 8/200] [Batch 300/600] [D loss: -0.124778] [G loss: -0.496064]\n",
            "[Epoch 9/200] [Batch 0/600] [D loss: -0.081741] [G loss: -0.506093]\n",
            "[Epoch 9/200] [Batch 300/600] [D loss: -0.091889] [G loss: -0.503414]\n",
            "[Epoch 10/200] [Batch 0/600] [D loss: -0.100684] [G loss: -0.500813]\n",
            "[Epoch 10/200] [Batch 300/600] [D loss: -0.094047] [G loss: -0.481043]\n",
            "[Epoch 11/200] [Batch 0/600] [D loss: -0.079922] [G loss: -0.520086]\n",
            "[Epoch 11/200] [Batch 300/600] [D loss: -0.106199] [G loss: -0.500047]\n",
            "[Epoch 12/200] [Batch 0/600] [D loss: -0.069805] [G loss: -0.528858]\n",
            "[Epoch 12/200] [Batch 300/600] [D loss: -0.075887] [G loss: -0.514410]\n",
            "[Epoch 13/200] [Batch 0/600] [D loss: -0.091727] [G loss: -0.497459]\n",
            "[Epoch 13/200] [Batch 300/600] [D loss: -0.074941] [G loss: -0.532753]\n",
            "[Epoch 14/200] [Batch 0/600] [D loss: -0.098233] [G loss: -0.474961]\n",
            "[Epoch 14/200] [Batch 300/600] [D loss: -0.078555] [G loss: -0.493982]\n",
            "[Epoch 15/200] [Batch 0/600] [D loss: -0.086161] [G loss: -0.502661]\n",
            "[Epoch 15/200] [Batch 300/600] [D loss: -0.079888] [G loss: -0.517668]\n",
            "[Epoch 16/200] [Batch 0/600] [D loss: -0.089117] [G loss: -0.500814]\n",
            "[Epoch 16/200] [Batch 300/600] [D loss: -0.089368] [G loss: -0.503700]\n",
            "[Epoch 17/200] [Batch 0/600] [D loss: -0.079303] [G loss: -0.513967]\n",
            "[Epoch 17/200] [Batch 300/600] [D loss: -0.077175] [G loss: -0.495028]\n",
            "[Epoch 18/200] [Batch 0/600] [D loss: -0.085619] [G loss: -0.490913]\n",
            "[Epoch 18/200] [Batch 300/600] [D loss: -0.090874] [G loss: -0.490331]\n",
            "[Epoch 19/200] [Batch 0/600] [D loss: -0.089647] [G loss: -0.506890]\n",
            "[Epoch 19/200] [Batch 300/600] [D loss: -0.083110] [G loss: -0.494001]\n",
            "[Epoch 20/200] [Batch 0/600] [D loss: -0.072458] [G loss: -0.506914]\n",
            "[Epoch 20/200] [Batch 300/600] [D loss: -0.090514] [G loss: -0.495310]\n",
            "[Epoch 21/200] [Batch 0/600] [D loss: -0.076167] [G loss: -0.498376]\n",
            "[Epoch 21/200] [Batch 300/600] [D loss: -0.068645] [G loss: -0.511325]\n",
            "[Epoch 22/200] [Batch 0/600] [D loss: -0.085801] [G loss: -0.486146]\n",
            "[Epoch 22/200] [Batch 300/600] [D loss: -0.098098] [G loss: -0.474784]\n",
            "[Epoch 23/200] [Batch 0/600] [D loss: -0.080760] [G loss: -0.507382]\n",
            "[Epoch 23/200] [Batch 300/600] [D loss: -0.079148] [G loss: -0.499368]\n",
            "[Epoch 24/200] [Batch 0/600] [D loss: -0.073801] [G loss: -0.521060]\n",
            "[Epoch 24/200] [Batch 300/600] [D loss: -0.068686] [G loss: -0.516599]\n",
            "[Epoch 25/200] [Batch 0/600] [D loss: -0.071568] [G loss: -0.512248]\n",
            "[Epoch 25/200] [Batch 300/600] [D loss: -0.076038] [G loss: -0.500376]\n",
            "[Epoch 26/200] [Batch 0/600] [D loss: -0.076939] [G loss: -0.506115]\n",
            "[Epoch 26/200] [Batch 300/600] [D loss: -0.057456] [G loss: -0.527777]\n",
            "[Epoch 27/200] [Batch 0/600] [D loss: -0.078122] [G loss: -0.501250]\n",
            "[Epoch 27/200] [Batch 300/600] [D loss: -0.064029] [G loss: -0.498692]\n",
            "[Epoch 28/200] [Batch 0/600] [D loss: -0.067969] [G loss: -0.503852]\n",
            "[Epoch 28/200] [Batch 300/600] [D loss: -0.068107] [G loss: -0.506368]\n",
            "[Epoch 29/200] [Batch 0/600] [D loss: -0.072151] [G loss: -0.505436]\n",
            "[Epoch 29/200] [Batch 300/600] [D loss: -0.066837] [G loss: -0.512753]\n",
            "[Epoch 30/200] [Batch 0/600] [D loss: -0.068613] [G loss: -0.510562]\n",
            "[Epoch 30/200] [Batch 300/600] [D loss: -0.063189] [G loss: -0.513243]\n",
            "[Epoch 31/200] [Batch 0/600] [D loss: -0.065253] [G loss: -0.503645]\n",
            "[Epoch 31/200] [Batch 300/600] [D loss: -0.072682] [G loss: -0.498087]\n",
            "[Epoch 32/200] [Batch 0/600] [D loss: -0.061337] [G loss: -0.502987]\n",
            "[Epoch 32/200] [Batch 300/600] [D loss: -0.063108] [G loss: -0.521165]\n",
            "[Epoch 33/200] [Batch 0/600] [D loss: -0.070548] [G loss: -0.500445]\n",
            "[Epoch 33/200] [Batch 300/600] [D loss: -0.064104] [G loss: -0.504190]\n",
            "[Epoch 34/200] [Batch 0/600] [D loss: -0.066288] [G loss: -0.498425]\n",
            "[Epoch 34/200] [Batch 300/600] [D loss: -0.058985] [G loss: -0.515590]\n",
            "[Epoch 35/200] [Batch 0/600] [D loss: -0.060482] [G loss: -0.503915]\n",
            "[Epoch 35/200] [Batch 300/600] [D loss: -0.059705] [G loss: -0.511684]\n",
            "[Epoch 36/200] [Batch 0/600] [D loss: -0.056756] [G loss: -0.511787]\n",
            "[Epoch 36/200] [Batch 300/600] [D loss: -0.060752] [G loss: -0.508851]\n",
            "[Epoch 37/200] [Batch 0/600] [D loss: -0.061769] [G loss: -0.501198]\n",
            "[Epoch 37/200] [Batch 300/600] [D loss: -0.060782] [G loss: -0.518135]\n",
            "[Epoch 38/200] [Batch 0/600] [D loss: -0.058698] [G loss: -0.515290]\n",
            "[Epoch 38/200] [Batch 300/600] [D loss: -0.053162] [G loss: -0.501051]\n",
            "[Epoch 39/200] [Batch 0/600] [D loss: -0.059636] [G loss: -0.493152]\n",
            "[Epoch 39/200] [Batch 300/600] [D loss: -0.062699] [G loss: -0.501387]\n",
            "[Epoch 40/200] [Batch 0/600] [D loss: -0.057187] [G loss: -0.500279]\n",
            "[Epoch 40/200] [Batch 300/600] [D loss: -0.054170] [G loss: -0.498385]\n",
            "[Epoch 41/200] [Batch 0/600] [D loss: -0.060392] [G loss: -0.505106]\n",
            "[Epoch 41/200] [Batch 300/600] [D loss: -0.054553] [G loss: -0.501681]\n",
            "[Epoch 42/200] [Batch 0/600] [D loss: -0.057558] [G loss: -0.501583]\n",
            "[Epoch 42/200] [Batch 300/600] [D loss: -0.058747] [G loss: -0.495894]\n",
            "[Epoch 43/200] [Batch 0/600] [D loss: -0.059002] [G loss: -0.489834]\n",
            "[Epoch 43/200] [Batch 300/600] [D loss: -0.054846] [G loss: -0.494897]\n",
            "[Epoch 44/200] [Batch 0/600] [D loss: -0.056661] [G loss: -0.498884]\n",
            "[Epoch 44/200] [Batch 300/600] [D loss: -0.059097] [G loss: -0.500020]\n",
            "[Epoch 45/200] [Batch 0/600] [D loss: -0.063060] [G loss: -0.487039]\n",
            "[Epoch 45/200] [Batch 300/600] [D loss: -0.064533] [G loss: -0.485833]\n",
            "[Epoch 46/200] [Batch 0/600] [D loss: -0.054525] [G loss: -0.504007]\n",
            "[Epoch 46/200] [Batch 300/600] [D loss: -0.056700] [G loss: -0.501285]\n",
            "[Epoch 47/200] [Batch 0/600] [D loss: -0.054843] [G loss: -0.497072]\n",
            "[Epoch 47/200] [Batch 300/600] [D loss: -0.059266] [G loss: -0.483452]\n",
            "[Epoch 48/200] [Batch 0/600] [D loss: -0.059512] [G loss: -0.491897]\n",
            "[Epoch 48/200] [Batch 300/600] [D loss: -0.052823] [G loss: -0.502832]\n",
            "[Epoch 49/200] [Batch 0/600] [D loss: -0.058092] [G loss: -0.488564]\n",
            "[Epoch 49/200] [Batch 300/600] [D loss: -0.055335] [G loss: -0.495451]\n",
            "[Epoch 50/200] [Batch 0/600] [D loss: -0.056210] [G loss: -0.494605]\n",
            "[Epoch 50/200] [Batch 300/600] [D loss: -0.051567] [G loss: -0.502677]\n",
            "[Epoch 51/200] [Batch 0/600] [D loss: -0.050533] [G loss: -0.491083]\n",
            "[Epoch 51/200] [Batch 300/600] [D loss: -0.054073] [G loss: -0.502026]\n",
            "[Epoch 52/200] [Batch 0/600] [D loss: -0.052159] [G loss: -0.493544]\n",
            "[Epoch 52/200] [Batch 300/600] [D loss: -0.060803] [G loss: -0.490895]\n",
            "[Epoch 53/200] [Batch 0/600] [D loss: -0.058515] [G loss: -0.494567]\n",
            "[Epoch 53/200] [Batch 300/600] [D loss: -0.057406] [G loss: -0.488274]\n",
            "[Epoch 54/200] [Batch 0/600] [D loss: -0.052127] [G loss: -0.488878]\n",
            "[Epoch 54/200] [Batch 300/600] [D loss: -0.053461] [G loss: -0.497574]\n",
            "[Epoch 55/200] [Batch 0/600] [D loss: -0.051410] [G loss: -0.497250]\n",
            "[Epoch 55/200] [Batch 300/600] [D loss: -0.054558] [G loss: -0.499257]\n",
            "[Epoch 56/200] [Batch 0/600] [D loss: -0.054087] [G loss: -0.494853]\n",
            "[Epoch 56/200] [Batch 300/600] [D loss: -0.050164] [G loss: -0.490331]\n",
            "[Epoch 57/200] [Batch 0/600] [D loss: -0.050834] [G loss: -0.491715]\n",
            "[Epoch 57/200] [Batch 300/600] [D loss: -0.056735] [G loss: -0.488357]\n",
            "[Epoch 58/200] [Batch 0/600] [D loss: -0.053718] [G loss: -0.501381]\n",
            "[Epoch 58/200] [Batch 300/600] [D loss: -0.049611] [G loss: -0.496084]\n",
            "[Epoch 59/200] [Batch 0/600] [D loss: -0.055721] [G loss: -0.485568]\n",
            "[Epoch 59/200] [Batch 300/600] [D loss: -0.048804] [G loss: -0.496086]\n",
            "[Epoch 60/200] [Batch 0/600] [D loss: -0.056580] [G loss: -0.487804]\n",
            "[Epoch 60/200] [Batch 300/600] [D loss: -0.046386] [G loss: -0.498722]\n",
            "[Epoch 61/200] [Batch 0/600] [D loss: -0.051375] [G loss: -0.474096]\n",
            "[Epoch 61/200] [Batch 300/600] [D loss: -0.055743] [G loss: -0.482857]\n",
            "[Epoch 62/200] [Batch 0/600] [D loss: -0.050188] [G loss: -0.493579]\n",
            "[Epoch 62/200] [Batch 300/600] [D loss: -0.053227] [G loss: -0.493080]\n",
            "[Epoch 63/200] [Batch 0/600] [D loss: -0.053968] [G loss: -0.493469]\n",
            "[Epoch 63/200] [Batch 300/600] [D loss: -0.056095] [G loss: -0.488605]\n",
            "[Epoch 64/200] [Batch 0/600] [D loss: -0.050842] [G loss: -0.482657]\n",
            "[Epoch 64/200] [Batch 300/600] [D loss: -0.048543] [G loss: -0.497944]\n",
            "[Epoch 65/200] [Batch 0/600] [D loss: -0.043356] [G loss: -0.494635]\n",
            "[Epoch 65/200] [Batch 300/600] [D loss: -0.049046] [G loss: -0.487769]\n",
            "[Epoch 66/200] [Batch 0/600] [D loss: -0.050128] [G loss: -0.488958]\n",
            "[Epoch 66/200] [Batch 300/600] [D loss: -0.044490] [G loss: -0.491267]\n",
            "[Epoch 67/200] [Batch 0/600] [D loss: -0.057299] [G loss: -0.485418]\n",
            "[Epoch 67/200] [Batch 300/600] [D loss: -0.049471] [G loss: -0.490120]\n",
            "[Epoch 68/200] [Batch 0/600] [D loss: -0.048008] [G loss: -0.481564]\n",
            "[Epoch 68/200] [Batch 300/600] [D loss: -0.049523] [G loss: -0.491744]\n",
            "[Epoch 69/200] [Batch 0/600] [D loss: -0.045373] [G loss: -0.492374]\n",
            "[Epoch 69/200] [Batch 300/600] [D loss: -0.051513] [G loss: -0.486804]\n",
            "[Epoch 70/200] [Batch 0/600] [D loss: -0.048464] [G loss: -0.482316]\n",
            "[Epoch 70/200] [Batch 300/600] [D loss: -0.041961] [G loss: -0.494404]\n",
            "[Epoch 71/200] [Batch 0/600] [D loss: -0.046118] [G loss: -0.483169]\n",
            "[Epoch 71/200] [Batch 300/600] [D loss: -0.043895] [G loss: -0.496444]\n",
            "[Epoch 72/200] [Batch 0/600] [D loss: -0.047172] [G loss: -0.486516]\n",
            "[Epoch 72/200] [Batch 300/600] [D loss: -0.048666] [G loss: -0.483901]\n",
            "[Epoch 73/200] [Batch 0/600] [D loss: -0.043930] [G loss: -0.486231]\n",
            "[Epoch 73/200] [Batch 300/600] [D loss: -0.048306] [G loss: -0.486996]\n",
            "[Epoch 74/200] [Batch 0/600] [D loss: -0.049243] [G loss: -0.492781]\n",
            "[Epoch 74/200] [Batch 300/600] [D loss: -0.042835] [G loss: -0.486222]\n",
            "[Epoch 75/200] [Batch 0/600] [D loss: -0.049901] [G loss: -0.489348]\n",
            "[Epoch 75/200] [Batch 300/600] [D loss: -0.046192] [G loss: -0.476905]\n",
            "[Epoch 76/200] [Batch 0/600] [D loss: -0.044734] [G loss: -0.485369]\n",
            "[Epoch 76/200] [Batch 300/600] [D loss: -0.053340] [G loss: -0.483388]\n",
            "[Epoch 77/200] [Batch 0/600] [D loss: -0.042361] [G loss: -0.486542]\n",
            "[Epoch 77/200] [Batch 300/600] [D loss: -0.051917] [G loss: -0.475986]\n",
            "[Epoch 78/200] [Batch 0/600] [D loss: -0.047917] [G loss: -0.490309]\n",
            "[Epoch 78/200] [Batch 300/600] [D loss: -0.048653] [G loss: -0.487362]\n",
            "[Epoch 79/200] [Batch 0/600] [D loss: -0.038912] [G loss: -0.490770]\n",
            "[Epoch 79/200] [Batch 300/600] [D loss: -0.044990] [G loss: -0.481770]\n",
            "[Epoch 80/200] [Batch 0/600] [D loss: -0.049269] [G loss: -0.485805]\n",
            "[Epoch 80/200] [Batch 300/600] [D loss: -0.041467] [G loss: -0.477375]\n",
            "[Epoch 81/200] [Batch 0/600] [D loss: -0.054563] [G loss: -0.471455]\n",
            "[Epoch 81/200] [Batch 300/600] [D loss: -0.044630] [G loss: -0.491966]\n",
            "[Epoch 82/200] [Batch 0/600] [D loss: -0.042784] [G loss: -0.490360]\n",
            "[Epoch 82/200] [Batch 300/600] [D loss: -0.053303] [G loss: -0.484877]\n",
            "[Epoch 83/200] [Batch 0/600] [D loss: -0.047723] [G loss: -0.480757]\n",
            "[Epoch 83/200] [Batch 300/600] [D loss: -0.053287] [G loss: -0.476544]\n",
            "[Epoch 84/200] [Batch 0/600] [D loss: -0.052560] [G loss: -0.483616]\n",
            "[Epoch 84/200] [Batch 300/600] [D loss: -0.044845] [G loss: -0.487102]\n",
            "[Epoch 85/200] [Batch 0/600] [D loss: -0.047957] [G loss: -0.485765]\n",
            "[Epoch 85/200] [Batch 300/600] [D loss: -0.045661] [G loss: -0.479871]\n",
            "[Epoch 86/200] [Batch 0/600] [D loss: -0.044952] [G loss: -0.476323]\n",
            "[Epoch 86/200] [Batch 300/600] [D loss: -0.047537] [G loss: -0.487894]\n",
            "[Epoch 87/200] [Batch 0/600] [D loss: -0.049281] [G loss: -0.478581]\n",
            "[Epoch 87/200] [Batch 300/600] [D loss: -0.042842] [G loss: -0.486367]\n",
            "[Epoch 88/200] [Batch 0/600] [D loss: -0.051061] [G loss: -0.476286]\n",
            "[Epoch 88/200] [Batch 300/600] [D loss: -0.047233] [G loss: -0.480906]\n",
            "[Epoch 89/200] [Batch 0/600] [D loss: -0.047681] [G loss: -0.472941]\n",
            "[Epoch 89/200] [Batch 300/600] [D loss: -0.041941] [G loss: -0.488468]\n",
            "[Epoch 90/200] [Batch 0/600] [D loss: -0.041606] [G loss: -0.481054]\n",
            "[Epoch 90/200] [Batch 300/600] [D loss: -0.042619] [G loss: -0.480426]\n",
            "[Epoch 91/200] [Batch 0/600] [D loss: -0.041412] [G loss: -0.485371]\n",
            "[Epoch 91/200] [Batch 300/600] [D loss: -0.043642] [G loss: -0.490134]\n",
            "[Epoch 92/200] [Batch 0/600] [D loss: -0.040938] [G loss: -0.491205]\n",
            "[Epoch 92/200] [Batch 300/600] [D loss: -0.042321] [G loss: -0.490275]\n",
            "[Epoch 93/200] [Batch 0/600] [D loss: -0.033798] [G loss: -0.492588]\n",
            "[Epoch 93/200] [Batch 300/600] [D loss: -0.045532] [G loss: -0.484400]\n",
            "[Epoch 94/200] [Batch 0/600] [D loss: -0.046490] [G loss: -0.478978]\n",
            "[Epoch 94/200] [Batch 300/600] [D loss: -0.041762] [G loss: -0.486889]\n",
            "[Epoch 95/200] [Batch 0/600] [D loss: -0.040986] [G loss: -0.480323]\n",
            "[Epoch 95/200] [Batch 300/600] [D loss: -0.044833] [G loss: -0.488010]\n",
            "[Epoch 96/200] [Batch 0/600] [D loss: -0.044000] [G loss: -0.478854]\n",
            "[Epoch 96/200] [Batch 300/600] [D loss: -0.042082] [G loss: -0.482922]\n",
            "[Epoch 97/200] [Batch 0/600] [D loss: -0.047912] [G loss: -0.478601]\n",
            "[Epoch 97/200] [Batch 300/600] [D loss: -0.041214] [G loss: -0.483817]\n",
            "[Epoch 98/200] [Batch 0/600] [D loss: -0.040050] [G loss: -0.482515]\n",
            "[Epoch 98/200] [Batch 300/600] [D loss: -0.042907] [G loss: -0.481249]\n",
            "[Epoch 99/200] [Batch 0/600] [D loss: -0.040648] [G loss: -0.484018]\n",
            "[Epoch 99/200] [Batch 300/600] [D loss: -0.037008] [G loss: -0.491635]\n",
            "[Epoch 100/200] [Batch 0/600] [D loss: -0.037472] [G loss: -0.484588]\n",
            "[Epoch 100/200] [Batch 300/600] [D loss: -0.040998] [G loss: -0.486884]\n",
            "[Epoch 101/200] [Batch 0/600] [D loss: -0.043907] [G loss: -0.491708]\n",
            "[Epoch 101/200] [Batch 300/600] [D loss: -0.036899] [G loss: -0.492489]\n",
            "[Epoch 102/200] [Batch 0/600] [D loss: -0.045801] [G loss: -0.475651]\n",
            "[Epoch 102/200] [Batch 300/600] [D loss: -0.037730] [G loss: -0.488787]\n",
            "[Epoch 103/200] [Batch 0/600] [D loss: -0.038085] [G loss: -0.473762]\n",
            "[Epoch 103/200] [Batch 300/600] [D loss: -0.034188] [G loss: -0.486220]\n",
            "[Epoch 104/200] [Batch 0/600] [D loss: -0.033434] [G loss: -0.487564]\n",
            "[Epoch 104/200] [Batch 300/600] [D loss: -0.038881] [G loss: -0.483260]\n",
            "[Epoch 105/200] [Batch 0/600] [D loss: -0.039909] [G loss: -0.476652]\n",
            "[Epoch 105/200] [Batch 300/600] [D loss: -0.035736] [G loss: -0.486004]\n",
            "[Epoch 106/200] [Batch 0/600] [D loss: -0.037558] [G loss: -0.486951]\n",
            "[Epoch 106/200] [Batch 300/600] [D loss: -0.037414] [G loss: -0.483174]\n",
            "[Epoch 107/200] [Batch 0/600] [D loss: -0.033771] [G loss: -0.479658]\n",
            "[Epoch 107/200] [Batch 300/600] [D loss: -0.037842] [G loss: -0.486949]\n",
            "[Epoch 108/200] [Batch 0/600] [D loss: -0.034721] [G loss: -0.481498]\n",
            "[Epoch 108/200] [Batch 300/600] [D loss: -0.032905] [G loss: -0.484747]\n",
            "[Epoch 109/200] [Batch 0/600] [D loss: -0.036633] [G loss: -0.484432]\n",
            "[Epoch 109/200] [Batch 300/600] [D loss: -0.037224] [G loss: -0.478407]\n",
            "[Epoch 110/200] [Batch 0/600] [D loss: -0.042365] [G loss: -0.476410]\n",
            "[Epoch 110/200] [Batch 300/600] [D loss: -0.041184] [G loss: -0.488850]\n",
            "[Epoch 111/200] [Batch 0/600] [D loss: -0.032724] [G loss: -0.494881]\n",
            "[Epoch 111/200] [Batch 300/600] [D loss: -0.046866] [G loss: -0.472734]\n",
            "[Epoch 112/200] [Batch 0/600] [D loss: -0.035220] [G loss: -0.483903]\n",
            "[Epoch 112/200] [Batch 300/600] [D loss: -0.041034] [G loss: -0.479494]\n",
            "[Epoch 113/200] [Batch 0/600] [D loss: -0.035407] [G loss: -0.480497]\n",
            "[Epoch 113/200] [Batch 300/600] [D loss: -0.033803] [G loss: -0.494557]\n",
            "[Epoch 114/200] [Batch 0/600] [D loss: -0.035269] [G loss: -0.489059]\n",
            "[Epoch 114/200] [Batch 300/600] [D loss: -0.036259] [G loss: -0.487680]\n",
            "[Epoch 115/200] [Batch 0/600] [D loss: -0.034313] [G loss: -0.489382]\n",
            "[Epoch 115/200] [Batch 300/600] [D loss: -0.037370] [G loss: -0.491185]\n",
            "[Epoch 116/200] [Batch 0/600] [D loss: -0.032412] [G loss: -0.488063]\n",
            "[Epoch 116/200] [Batch 300/600] [D loss: -0.033883] [G loss: -0.476346]\n",
            "[Epoch 117/200] [Batch 0/600] [D loss: -0.034263] [G loss: -0.484582]\n",
            "[Epoch 117/200] [Batch 300/600] [D loss: -0.034521] [G loss: -0.487988]\n",
            "[Epoch 118/200] [Batch 0/600] [D loss: -0.037015] [G loss: -0.487822]\n",
            "[Epoch 118/200] [Batch 300/600] [D loss: -0.035148] [G loss: -0.497265]\n",
            "[Epoch 119/200] [Batch 0/600] [D loss: -0.033361] [G loss: -0.480468]\n",
            "[Epoch 119/200] [Batch 300/600] [D loss: -0.041566] [G loss: -0.485965]\n",
            "[Epoch 120/200] [Batch 0/600] [D loss: -0.032229] [G loss: -0.486048]\n",
            "[Epoch 120/200] [Batch 300/600] [D loss: -0.033201] [G loss: -0.489269]\n",
            "[Epoch 121/200] [Batch 0/600] [D loss: -0.034351] [G loss: -0.486637]\n",
            "[Epoch 121/200] [Batch 300/600] [D loss: -0.039599] [G loss: -0.476526]\n",
            "[Epoch 122/200] [Batch 0/600] [D loss: -0.034520] [G loss: -0.484864]\n",
            "[Epoch 122/200] [Batch 300/600] [D loss: -0.032222] [G loss: -0.490371]\n",
            "[Epoch 123/200] [Batch 0/600] [D loss: -0.033558] [G loss: -0.479331]\n",
            "[Epoch 123/200] [Batch 300/600] [D loss: -0.036450] [G loss: -0.493755]\n",
            "[Epoch 124/200] [Batch 0/600] [D loss: -0.032880] [G loss: -0.482694]\n",
            "[Epoch 124/200] [Batch 300/600] [D loss: -0.035738] [G loss: -0.480605]\n",
            "[Epoch 125/200] [Batch 0/600] [D loss: -0.029404] [G loss: -0.487142]\n",
            "[Epoch 125/200] [Batch 300/600] [D loss: -0.032481] [G loss: -0.484736]\n",
            "[Epoch 126/200] [Batch 0/600] [D loss: -0.036836] [G loss: -0.485085]\n",
            "[Epoch 126/200] [Batch 300/600] [D loss: -0.032078] [G loss: -0.493934]\n",
            "[Epoch 127/200] [Batch 0/600] [D loss: -0.035627] [G loss: -0.487174]\n",
            "[Epoch 127/200] [Batch 300/600] [D loss: -0.037149] [G loss: -0.478795]\n",
            "[Epoch 128/200] [Batch 0/600] [D loss: -0.038345] [G loss: -0.478830]\n",
            "[Epoch 128/200] [Batch 300/600] [D loss: -0.034299] [G loss: -0.485298]\n",
            "[Epoch 129/200] [Batch 0/600] [D loss: -0.030677] [G loss: -0.484192]\n",
            "[Epoch 129/200] [Batch 300/600] [D loss: -0.033073] [G loss: -0.482596]\n",
            "[Epoch 130/200] [Batch 0/600] [D loss: -0.037920] [G loss: -0.471933]\n",
            "[Epoch 130/200] [Batch 300/600] [D loss: -0.032429] [G loss: -0.486163]\n",
            "[Epoch 131/200] [Batch 0/600] [D loss: -0.031744] [G loss: -0.489598]\n",
            "[Epoch 131/200] [Batch 300/600] [D loss: -0.032215] [G loss: -0.491017]\n",
            "[Epoch 132/200] [Batch 0/600] [D loss: -0.033111] [G loss: -0.494706]\n",
            "[Epoch 132/200] [Batch 300/600] [D loss: -0.029395] [G loss: -0.494133]\n",
            "[Epoch 133/200] [Batch 0/600] [D loss: -0.030404] [G loss: -0.501287]\n",
            "[Epoch 133/200] [Batch 300/600] [D loss: -0.034391] [G loss: -0.497614]\n",
            "[Epoch 134/200] [Batch 0/600] [D loss: -0.028457] [G loss: -0.486981]\n",
            "[Epoch 134/200] [Batch 300/600] [D loss: -0.034441] [G loss: -0.491423]\n",
            "[Epoch 135/200] [Batch 0/600] [D loss: -0.032567] [G loss: -0.484561]\n",
            "[Epoch 135/200] [Batch 300/600] [D loss: -0.030718] [G loss: -0.480686]\n",
            "[Epoch 136/200] [Batch 0/600] [D loss: -0.034323] [G loss: -0.489720]\n",
            "[Epoch 136/200] [Batch 300/600] [D loss: -0.028956] [G loss: -0.490388]\n",
            "[Epoch 137/200] [Batch 0/600] [D loss: -0.030395] [G loss: -0.489604]\n",
            "[Epoch 137/200] [Batch 300/600] [D loss: -0.032433] [G loss: -0.494133]\n",
            "[Epoch 138/200] [Batch 0/600] [D loss: -0.029402] [G loss: -0.486949]\n",
            "[Epoch 138/200] [Batch 300/600] [D loss: -0.031488] [G loss: -0.487387]\n",
            "[Epoch 139/200] [Batch 0/600] [D loss: -0.035300] [G loss: -0.493526]\n",
            "[Epoch 139/200] [Batch 300/600] [D loss: -0.026896] [G loss: -0.493986]\n",
            "[Epoch 140/200] [Batch 0/600] [D loss: -0.031171] [G loss: -0.490905]\n",
            "[Epoch 140/200] [Batch 300/600] [D loss: -0.033418] [G loss: -0.489955]\n",
            "[Epoch 141/200] [Batch 0/600] [D loss: -0.031728] [G loss: -0.495820]\n",
            "[Epoch 141/200] [Batch 300/600] [D loss: -0.029069] [G loss: -0.499717]\n",
            "[Epoch 142/200] [Batch 0/600] [D loss: -0.026792] [G loss: -0.485405]\n",
            "[Epoch 142/200] [Batch 300/600] [D loss: -0.030701] [G loss: -0.507616]\n",
            "[Epoch 143/200] [Batch 0/600] [D loss: -0.032564] [G loss: -0.481803]\n",
            "[Epoch 143/200] [Batch 300/600] [D loss: -0.029830] [G loss: -0.474294]\n",
            "[Epoch 144/200] [Batch 0/600] [D loss: -0.032635] [G loss: -0.483877]\n",
            "[Epoch 144/200] [Batch 300/600] [D loss: -0.029779] [G loss: -0.482734]\n",
            "[Epoch 145/200] [Batch 0/600] [D loss: -0.030692] [G loss: -0.487768]\n",
            "[Epoch 145/200] [Batch 300/600] [D loss: -0.033882] [G loss: -0.481680]\n",
            "[Epoch 146/200] [Batch 0/600] [D loss: -0.029155] [G loss: -0.487680]\n",
            "[Epoch 146/200] [Batch 300/600] [D loss: -0.027083] [G loss: -0.504601]\n",
            "[Epoch 147/200] [Batch 0/600] [D loss: -0.025220] [G loss: -0.494909]\n",
            "[Epoch 147/200] [Batch 300/600] [D loss: -0.030498] [G loss: -0.494843]\n",
            "[Epoch 148/200] [Batch 0/600] [D loss: -0.030002] [G loss: -0.488255]\n",
            "[Epoch 148/200] [Batch 300/600] [D loss: -0.031040] [G loss: -0.482296]\n",
            "[Epoch 149/200] [Batch 0/600] [D loss: -0.032239] [G loss: -0.506012]\n",
            "[Epoch 149/200] [Batch 300/600] [D loss: -0.028746] [G loss: -0.494410]\n",
            "[Epoch 150/200] [Batch 0/600] [D loss: -0.028141] [G loss: -0.478645]\n",
            "[Epoch 150/200] [Batch 300/600] [D loss: -0.029029] [G loss: -0.481382]\n",
            "[Epoch 151/200] [Batch 0/600] [D loss: -0.031118] [G loss: -0.479233]\n",
            "[Epoch 151/200] [Batch 300/600] [D loss: -0.028313] [G loss: -0.495881]\n",
            "[Epoch 152/200] [Batch 0/600] [D loss: -0.027287] [G loss: -0.498220]\n",
            "[Epoch 152/200] [Batch 300/600] [D loss: -0.031518] [G loss: -0.508183]\n",
            "[Epoch 153/200] [Batch 0/600] [D loss: -0.033015] [G loss: -0.498194]\n",
            "[Epoch 153/200] [Batch 300/600] [D loss: -0.024446] [G loss: -0.500943]\n",
            "[Epoch 154/200] [Batch 0/600] [D loss: -0.029063] [G loss: -0.489250]\n",
            "[Epoch 154/200] [Batch 300/600] [D loss: -0.031251] [G loss: -0.485247]\n",
            "[Epoch 155/200] [Batch 0/600] [D loss: -0.031423] [G loss: -0.491829]\n",
            "[Epoch 155/200] [Batch 300/600] [D loss: -0.024453] [G loss: -0.489019]\n",
            "[Epoch 156/200] [Batch 0/600] [D loss: -0.028961] [G loss: -0.483506]\n",
            "[Epoch 156/200] [Batch 300/600] [D loss: -0.025876] [G loss: -0.486147]\n",
            "[Epoch 157/200] [Batch 0/600] [D loss: -0.027733] [G loss: -0.494731]\n",
            "[Epoch 157/200] [Batch 300/600] [D loss: -0.029095] [G loss: -0.487478]\n",
            "[Epoch 158/200] [Batch 0/600] [D loss: -0.025938] [G loss: -0.504102]\n",
            "[Epoch 158/200] [Batch 300/600] [D loss: -0.033076] [G loss: -0.479317]\n",
            "[Epoch 159/200] [Batch 0/600] [D loss: -0.031800] [G loss: -0.508935]\n",
            "[Epoch 159/200] [Batch 300/600] [D loss: -0.028776] [G loss: -0.491033]\n",
            "[Epoch 160/200] [Batch 0/600] [D loss: -0.026663] [G loss: -0.489617]\n",
            "[Epoch 160/200] [Batch 300/600] [D loss: -0.030141] [G loss: -0.496791]\n",
            "[Epoch 161/200] [Batch 0/600] [D loss: -0.025438] [G loss: -0.480767]\n",
            "[Epoch 161/200] [Batch 300/600] [D loss: -0.026206] [G loss: -0.486710]\n",
            "[Epoch 162/200] [Batch 0/600] [D loss: -0.027790] [G loss: -0.487062]\n",
            "[Epoch 162/200] [Batch 300/600] [D loss: -0.024672] [G loss: -0.493366]\n",
            "[Epoch 163/200] [Batch 0/600] [D loss: -0.022231] [G loss: -0.496802]\n",
            "[Epoch 163/200] [Batch 300/600] [D loss: -0.026631] [G loss: -0.493660]\n",
            "[Epoch 164/200] [Batch 0/600] [D loss: -0.029137] [G loss: -0.486560]\n",
            "[Epoch 164/200] [Batch 300/600] [D loss: -0.027715] [G loss: -0.484408]\n",
            "[Epoch 165/200] [Batch 0/600] [D loss: -0.027385] [G loss: -0.499682]\n",
            "[Epoch 165/200] [Batch 300/600] [D loss: -0.027089] [G loss: -0.496618]\n",
            "[Epoch 166/200] [Batch 0/600] [D loss: -0.024967] [G loss: -0.485741]\n",
            "[Epoch 166/200] [Batch 300/600] [D loss: -0.027774] [G loss: -0.499131]\n",
            "[Epoch 167/200] [Batch 0/600] [D loss: -0.025422] [G loss: -0.490016]\n",
            "[Epoch 167/200] [Batch 300/600] [D loss: -0.024689] [G loss: -0.493459]\n",
            "[Epoch 168/200] [Batch 0/600] [D loss: -0.027367] [G loss: -0.492261]\n",
            "[Epoch 168/200] [Batch 300/600] [D loss: -0.030985] [G loss: -0.484558]\n",
            "[Epoch 169/200] [Batch 0/600] [D loss: -0.029649] [G loss: -0.486238]\n",
            "[Epoch 169/200] [Batch 300/600] [D loss: -0.030781] [G loss: -0.500201]\n",
            "[Epoch 170/200] [Batch 0/600] [D loss: -0.027083] [G loss: -0.489395]\n",
            "[Epoch 170/200] [Batch 300/600] [D loss: -0.023799] [G loss: -0.501802]\n",
            "[Epoch 171/200] [Batch 0/600] [D loss: -0.028977] [G loss: -0.489278]\n",
            "[Epoch 171/200] [Batch 300/600] [D loss: -0.028716] [G loss: -0.496081]\n",
            "[Epoch 172/200] [Batch 0/600] [D loss: -0.024407] [G loss: -0.494937]\n",
            "[Epoch 172/200] [Batch 300/600] [D loss: -0.026122] [G loss: -0.486756]\n",
            "[Epoch 173/200] [Batch 0/600] [D loss: -0.021380] [G loss: -0.495897]\n",
            "[Epoch 173/200] [Batch 300/600] [D loss: -0.027759] [G loss: -0.487404]\n",
            "[Epoch 174/200] [Batch 0/600] [D loss: -0.028585] [G loss: -0.488276]\n",
            "[Epoch 174/200] [Batch 300/600] [D loss: -0.025471] [G loss: -0.494707]\n",
            "[Epoch 175/200] [Batch 0/600] [D loss: -0.025753] [G loss: -0.491448]\n",
            "[Epoch 175/200] [Batch 300/600] [D loss: -0.028507] [G loss: -0.503828]\n",
            "[Epoch 176/200] [Batch 0/600] [D loss: -0.023132] [G loss: -0.486251]\n",
            "[Epoch 176/200] [Batch 300/600] [D loss: -0.027220] [G loss: -0.482195]\n",
            "[Epoch 177/200] [Batch 0/600] [D loss: -0.026098] [G loss: -0.490411]\n",
            "[Epoch 177/200] [Batch 300/600] [D loss: -0.026279] [G loss: -0.494021]\n",
            "[Epoch 178/200] [Batch 0/600] [D loss: -0.026404] [G loss: -0.485791]\n",
            "[Epoch 178/200] [Batch 300/600] [D loss: -0.023376] [G loss: -0.491206]\n",
            "[Epoch 179/200] [Batch 0/600] [D loss: -0.025933] [G loss: -0.483331]\n",
            "[Epoch 179/200] [Batch 300/600] [D loss: -0.020432] [G loss: -0.499336]\n",
            "[Epoch 180/200] [Batch 0/600] [D loss: -0.025981] [G loss: -0.501876]\n",
            "[Epoch 180/200] [Batch 300/600] [D loss: -0.024941] [G loss: -0.487587]\n",
            "[Epoch 181/200] [Batch 0/600] [D loss: -0.023841] [G loss: -0.500706]\n",
            "[Epoch 181/200] [Batch 300/600] [D loss: -0.024702] [G loss: -0.496114]\n",
            "[Epoch 182/200] [Batch 0/600] [D loss: -0.026508] [G loss: -0.499147]\n",
            "[Epoch 182/200] [Batch 300/600] [D loss: -0.022593] [G loss: -0.497660]\n",
            "[Epoch 183/200] [Batch 0/600] [D loss: -0.026812] [G loss: -0.498764]\n",
            "[Epoch 183/200] [Batch 300/600] [D loss: -0.025234] [G loss: -0.487521]\n",
            "[Epoch 184/200] [Batch 0/600] [D loss: -0.024877] [G loss: -0.494168]\n",
            "[Epoch 184/200] [Batch 300/600] [D loss: -0.025216] [G loss: -0.482614]\n",
            "[Epoch 185/200] [Batch 0/600] [D loss: -0.024660] [G loss: -0.503911]\n",
            "[Epoch 185/200] [Batch 300/600] [D loss: -0.022158] [G loss: -0.494107]\n",
            "[Epoch 186/200] [Batch 0/600] [D loss: -0.020477] [G loss: -0.496942]\n",
            "[Epoch 186/200] [Batch 300/600] [D loss: -0.018619] [G loss: -0.501049]\n",
            "[Epoch 187/200] [Batch 0/600] [D loss: -0.022193] [G loss: -0.496831]\n",
            "[Epoch 187/200] [Batch 300/600] [D loss: -0.020060] [G loss: -0.498553]\n",
            "[Epoch 188/200] [Batch 0/600] [D loss: -0.022207] [G loss: -0.504460]\n",
            "[Epoch 188/200] [Batch 300/600] [D loss: -0.024546] [G loss: -0.486498]\n",
            "[Epoch 189/200] [Batch 0/600] [D loss: -0.022936] [G loss: -0.496575]\n",
            "[Epoch 189/200] [Batch 300/600] [D loss: -0.017682] [G loss: -0.492295]\n",
            "[Epoch 190/200] [Batch 0/600] [D loss: -0.023853] [G loss: -0.505751]\n",
            "[Epoch 190/200] [Batch 300/600] [D loss: -0.021728] [G loss: -0.486104]\n",
            "[Epoch 191/200] [Batch 0/600] [D loss: -0.019779] [G loss: -0.481328]\n",
            "[Epoch 191/200] [Batch 300/600] [D loss: -0.023950] [G loss: -0.500393]\n",
            "[Epoch 192/200] [Batch 0/600] [D loss: -0.024324] [G loss: -0.495118]\n",
            "[Epoch 192/200] [Batch 300/600] [D loss: -0.019388] [G loss: -0.500785]\n",
            "[Epoch 193/200] [Batch 0/600] [D loss: -0.022548] [G loss: -0.502776]\n",
            "[Epoch 193/200] [Batch 300/600] [D loss: -0.022395] [G loss: -0.487589]\n",
            "[Epoch 194/200] [Batch 0/600] [D loss: -0.027085] [G loss: -0.488458]\n",
            "[Epoch 194/200] [Batch 300/600] [D loss: -0.021613] [G loss: -0.499856]\n",
            "[Epoch 195/200] [Batch 0/600] [D loss: -0.023729] [G loss: -0.494725]\n",
            "[Epoch 195/200] [Batch 300/600] [D loss: -0.017908] [G loss: -0.500656]\n",
            "[Epoch 196/200] [Batch 0/600] [D loss: -0.024396] [G loss: -0.507647]\n",
            "[Epoch 196/200] [Batch 300/600] [D loss: -0.028205] [G loss: -0.494361]\n",
            "[Epoch 197/200] [Batch 0/600] [D loss: -0.017011] [G loss: -0.492551]\n",
            "[Epoch 197/200] [Batch 300/600] [D loss: -0.024499] [G loss: -0.507469]\n",
            "[Epoch 198/200] [Batch 0/600] [D loss: -0.027433] [G loss: -0.496587]\n",
            "[Epoch 198/200] [Batch 300/600] [D loss: -0.025546] [G loss: -0.487457]\n",
            "[Epoch 199/200] [Batch 0/600] [D loss: -0.023273] [G loss: -0.485761]\n",
            "[Epoch 199/200] [Batch 300/600] [D loss: -0.023633] [G loss: -0.486418]\n"
          ]
        }
      ]
    }
  ]
}